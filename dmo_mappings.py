# -*- coding: utf-8 -*-
"""
Script para extrair mapeamentos de DMOs (Data Model Objects) do Salesforce Data Cloud.

Vers√£o Corrigida: Garante premissas de configura√ß√£o de rede id√™nticas ao script original.
- Valores padr√£o de USE_PROXY e VERIFY_SSL restaurados para o comportamento original.
"""
import os
import time
import asyncio
import csv
import logging
from urllib.parse import urljoin, urlencode

import jwt
import requests
import aiohttp
from dotenv import load_dotenv
from tqdm.asyncio import tqdm

# ==============================================================================
# --- ‚öôÔ∏è CONFIGURA√á√ÉO CENTRALIZADA (L√ìGICA ID√äNTICA AO ORIGINAL) ---
# ==============================================================================
load_dotenv()

class Config:
    """Classe de configura√ß√£o para centralizar os par√¢metros do script."""
    # Configura√ß√µes de Conex√£o com os MESMOS PADR√ïES do script original
    USE_PROXY = os.getenv("USE_PROXY", "True").lower() == "true"
    PROXY_URL = os.getenv("PROXY_URL")
    VERIFY_SSL = os.getenv("VERIFY_SSL", "False").lower() == "true"
    
    # Credenciais e Endpoints Salesforce
    API_VERSION = "v60.0"
    SF_CLIENT_ID = os.getenv("SF_CLIENT_ID")
    SF_USERNAME = os.getenv("SF_USERNAME")
    SF_AUDIENCE = os.getenv("SF_AUDIENCE")
    SF_LOGIN_URL = os.getenv("SF_LOGIN_URL")
    
    # Configura√ß√µes de Execu√ß√£o
    SEMAPHORE_LIMIT = 10
    MAX_RETRIES = 3
    RETRY_DELAY_SECONDS = 5
    
    # Arquivos de Sa√≠da
    OUTPUT_CSV_FILE = 'dmo_mappings.csv'
    LOG_FILE = 'mapping_extractor.log'

# ==============================================================================
# --- Ìó¨ FUN√á√ïES AUXILIARES E LOGGING ---
# ==============================================================================
def setup_logging(log_file):
    """Configura o sistema de logging para arquivo e console."""
    logger = logging.getLogger()
    if logger.hasHandlers(): logger.handlers.clear()
    logger.setLevel(logging.INFO)
    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
    file_handler = logging.FileHandler(log_file, mode='w', encoding='utf-8')
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)

def get_access_token(config: Config):
    """Obt√©m o token de acesso da Salesforce usando o fluxo JWT Bearer."""
    logging.info("üîë Autenticando com Salesforce via JWT...")
    try:
        with open('private.pem', 'r', encoding='utf-8') as f:
            private_key = f.read()
    except FileNotFoundError:
        logging.critical("‚ùå Arquivo 'private.pem' n√£o encontrado. Encerrando.")
        raise

    payload = {'iss': config.SF_CLIENT_ID, 'sub': config.SF_USERNAME, 'aud': config.SF_AUDIENCE, 'exp': int(time.time()) + 300}
    assertion = jwt.encode(payload, private_key, algorithm='RS256')
    params = {'grant_type': 'urn:ietf:params:oauth:grant-type:jwt-bearer', 'assertion': assertion}
    
    token_url = urljoin(config.SF_LOGIN_URL, "/services/oauth2/token")
    proxies = {'http': config.PROXY_URL, 'https': config.PROXY_URL} if config.USE_PROXY and config.PROXY_URL else None
    
    try:
        res = requests.post(token_url, data=params, proxies=proxies, verify=config.VERIFY_SSL, timeout=30)
        res.raise_for_status()
        logging.info("‚úÖ Autentica√ß√£o bem-sucedida.")
        return res.json()
    except requests.exceptions.RequestException as e:
        logging.critical(f"‚ùå Erro fatal na autentica√ß√£o: {e.response.text if e.response else e}")
        raise

# ==============================================================================
# --- üåê CLASSE CLIENTE SALESFORCE API ---
# ==============================================================================
class SalesforceClient:
    """Cliente ass√≠ncrono para interagir com as APIs da Salesforce."""
    def __init__(self, config: Config, auth_data: dict):
        self.config = config
        self.instance_url = auth_data.get('instance_url')
        self.headers = {'Authorization': f'Bearer {auth_data.get("access_token")}'}
        self.session = None
        self.semaphore = asyncio.Semaphore(config.SEMAPHORE_LIMIT)

    async def __aenter__(self):
        self.session = aiohttp.ClientSession(base_url=self.instance_url, headers=self.headers)
        return self

    async def __aexit__(self, exc_type, exc, tb):
        if self.session and not self.session.closed:
            await self.session.close()

    async def _fetch_with_retry(self, url, key_name=None):
        """M√©todo gen√©rico para buscar dados de um endpoint com retentativas e pagina√ß√£o."""
        async with self.semaphore:
            for attempt in range(self.config.MAX_RETRIES):
                try:
                    all_records, current_url = [], url
                    while current_url:
                        kwargs = {'ssl': self.config.VERIFY_SSL}
                        if self.config.USE_PROXY:
                            kwargs['proxy'] = self.config.PROXY_URL
                        
                        async with self.session.get(current_url, **kwargs) as response:
                            if response.status >= 400:
                                if response.status == 404:
                                    logging.warning(f"‚ö†Ô∏è  Recebido 404 (Not Found), tratando como resultado vazio para: {current_url}")
                                    return [] if key_name else None
                                error_text = await response.text()
                                logging.error(f"‚ùå Erro {response.status} para URL: {current_url}. Resposta: {error_text}")
                                response.raise_for_status()

                            data = await response.json()
                            if key_name:
                                all_records.extend(data.get(key_name, []))
                                next_url = data.get('nextRecordsUrl') or data.get('nextPageUrl')
                                current_url = urljoin(str(self.session._base_url), next_url) if next_url else None
                            else:
                                return data
                    return all_records
                except (aiohttp.ClientError, asyncio.TimeoutError) as e:
                    if attempt < self.config.MAX_RETRIES - 1:
                        logging.warning(f"Tentativa {attempt + 1} falhou para {url}. Causa: {e}. Tentando novamente...")
                        await asyncio.sleep(self.config.RETRY_DELAY_SECONDS)
                    else:
                        logging.error(f"‚ùå Falha ao buscar dados de {url} ap√≥s {self.config.MAX_RETRIES} tentativas.")
                        return [] if key_name else None

    async def get_ssot_endpoint(self, endpoint_path, key_name=None):
        url = f"/services/data/{self.config.API_VERSION}/ssot/{endpoint_path}"
        return await self._fetch_with_retry(url, key_name=key_name)

    async def fetch_dmo_mapping_details(self, dmo_api_name: str):
        params = {'dataspace': 'default', 'dmoDeveloperName': dmo_api_name}
        url_path = f"/services/data/{self.config.API_VERSION}/ssot/data-model-object-mappings?{urlencode(params)}"
        return await self._fetch_with_retry(url_path)

# ==============================================================================
# --- üöÄ ORQUESTRADOR PRINCIPAL (MAIN) ---
# ==============================================================================
async def main():
    """Fun√ß√£o principal que orquestra a extra√ß√£o e gera√ß√£o do CSV."""
    config = Config()
    setup_logging(config.LOG_FILE)
    
    logging.info("--- Verificando Configura√ß√µes de Rede (L√≥gica Original) ---")
    if config.USE_PROXY:
        logging.info(f"PROXY ATIVADO. Usando URL: {config.PROXY_URL}")
        if not config.PROXY_URL:
            logging.warning("!!! ATEN√á√ÉO: USE_PROXY=True, mas PROXY_URL n√£o est√° definido no arquivo .env. A conex√£o provavelmente falhar√°.")
    else:
        logging.info("PROXY DESATIVADO. Tentando conex√£o direta.")
    logging.info(f"Verifica√ß√£o de SSL: {config.VERIFY_SSL}")
    logging.info("----------------------------------------------------------")
    
    logging.info("üöÄ Iniciando extrator de mapeamentos de DMOs...")
    
    try:
        auth_data = get_access_token(config)
    except Exception:
        logging.critical("Falha na autentica√ß√£o. O script n√£o pode continuar.")
        return

    async with SalesforceClient(config, auth_data) as client:
        
        logging.info("--- Etapa 1/3: Buscando a lista de DMOs... ---")
        dmo_metadata = await client.get_ssot_endpoint("metadata?entityType=DataModelObject", key_name='metadata')
        
        if not dmo_metadata:
            logging.error("Nenhum metadado de DMO foi encontrado ou houve um erro na busca. Encerrando.")
            return
            
        dmo_names = sorted([dmo.get('name') for dmo in dmo_metadata if dmo.get('name')])
        logging.info(f"‚úÖ Encontrados {len(dmo_names)} DMOs para verificar.")

        logging.info("--- Etapa 2/3: Coletando os mapeamentos de cada DMO... ---")
        mapping_tasks = [client.fetch_dmo_mapping_details(name) for name in dmo_names]
        all_mappings_results = await tqdm.gather(*mapping_tasks, desc="Coletando mapeamentos")

        logging.info("--- Etapa 3/3: Processando resultados e gerando o arquivo CSV... ---")
        csv_data = []
        
        for dmo_name, payload in zip(dmo_names, all_mappings_results):
            if not payload or 'objectSourceTargetMaps' not in payload:
                continue
            
            mappings = payload.get('objectSourceTargetMaps', [])
            for mapping in mappings:
                csv_data.append({
                    'DMO_API_NAME': dmo_name,
                    'DLO_SOURCE': mapping.get('sourceEntityDeveloperName'),
                    'OBJECT_MAP_NAME': mapping.get('developerName')
                })

        if not csv_data:
            logging.warning("‚ö†Ô∏è Nenhum mapeamento foi encontrado para os DMOs verificados.")
            return

        try:
            fieldnames = ['DMO_API_NAME', 'DLO_SOURCE', 'OBJECT_MAP_NAME']
            with open(config.OUTPUT_CSV_FILE, 'w', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
                writer.writerows(csv_data)
            logging.info(f"‚úÖ Relat√≥rio '{config.OUTPUT_CSV_FILE}' gerado com sucesso, contendo {len(csv_data)} registros de mapeamento.")
        except IOError as e:
            logging.error(f"‚ùå Erro ao escrever o arquivo CSV: {e}")


if __name__ == "__main__":
    start_time = time.time()
    try:
        asyncio.run(main())
    except Exception as e:
        logging.critical(f"‚ùå Ocorreu um erro fatal na execu√ß√£o do script: {e}", exc_info=True)
    finally:
        duration = time.time() - start_time
        logging.info(f"\nüèÅ Execu√ß√£o conclu√≠da. Tempo total: {duration:.2f} segundos.")